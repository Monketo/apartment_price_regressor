{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://simple_user@localhost:5432/apartments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql_query('select * from apartments', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.to_file('./data_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['title','absolute_url', 'city_name', 'price_usd'],\n",
    "          axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper(string):\n",
    "    return sum(map(lambda x:x.isupper(), string)) if string else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuations(string):\n",
    "    return sum(map(lambda x:x in punctuation, string)) if string else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_images_attached'] = data['image_urls'].str.len()\n",
    "data['len_of_description'] = data['description'].str.len()\n",
    "data['num_of_uppercase_letters_in_description'] = data['description'].apply(count_upper) \n",
    "data['num_of_punctuations_in_description'] = data['description'].apply(count_upper) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['image_urls', 'description'],\n",
    "          axis=1,\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['construction_year'] = data.construction_period.str.extract(\"([\\d]{4})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['years_elapsed'] =  datetime.datetime.today().year - data['construction_year'].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['construction_year', 'construction_period'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_bargain'] = data.tags.apply(lambda  row : 'Торг' in row)\n",
    "data['is_used'] = data.tags.apply(lambda  row : 'Вторичное жилье' in row)\n",
    "data['is_not_used'] = data.tags.apply(lambda  row : 'Первичное жилье' in row)\n",
    "data['in_installments'] = data.tags.apply(lambda  row : 'Рассрочка/Кредит' in row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('tags',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['offer_type','wall_type','heating','city_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, target = data.drop(['price_uah'],axis=1), data[['price_uah']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers_ind(data, feature_name, is_positive=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate inliers indecies using IQR\n",
    "\n",
    "    :param data: pd.Dataframe\n",
    "    :param feature_name: feature\n",
    "    :param is_positive:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    q1 = data[feature_name].quantile(q=0.25)\n",
    "    q3 = data[feature_name].quantile(q=0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    if is_positive:\n",
    "        lower_bound = max(0, lower_bound)\n",
    "    mask = (data[feature_name] > upper_bound) | (data[feature_name] < lower_bound)\n",
    "    indecies = mask[mask == False].index\n",
    "    return set(indecies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_ind(data, feature_name):\n",
    "    return set(data[data[feature_name].isna()==False].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_indecies = list(drop_outliers('price_uah'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers_ind = get_inliers_ind(data,'price_uah')\n",
    "not_nan_ind = get_nan_ind(data, 'price_uah')\n",
    "inliers_ind = list(not_nan_ind & inliers_ind)\n",
    "data = data.loc[inliers_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing  part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['offer_type','wall_type','heating','city_id']\n",
    "bool_features = ['is_bargain','is_used', 'is_not_used', 'in_installments']\n",
    "num_features = [\n",
    "    \"position\",\n",
    "    \"len_of_description\",\n",
    "    \"floor_located\",\n",
    "    \"number_of_floors_in_the_house\",\n",
    "    \"longitude\",\n",
    "    \"apartment_area\",\n",
    "    \"years_elapsed\",\n",
    "    \"num_of_punctuations_in_description\",\n",
    "    \"number_rooms\",\n",
    "    \"latitude\",\n",
    "    \"num_of_uppercase_letters_in_description\",\n",
    "    \"number_of_images_attached\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoolTranformer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return np.array(X).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValuesImputer(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, cat_features, num_features, bool_features, \n",
    "                 categorical_imputation_dict=None,\n",
    "                 num_features_imputation_dict=None,\n",
    "                 bool_imputation_dict=None,\n",
    "                 default_cat_value = \"Uknown\",\n",
    "                 default_bool_value = False,\n",
    "                 default_num_value = 0\n",
    "                 ):\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        self.num_features = num_features\n",
    "        self.bool_features = bool_features\n",
    "       \n",
    "        dict_initializer = lambda given_dict: given_dict if type(given_dict) is dict else dict()\n",
    "        self.cat_feature_imputer = dict_initializer(categorical_imputation_dict)\n",
    "        self.num_feature_imputer = dict_initializer(num_features_imputation_dict)\n",
    "        self.bool_feature_imputer = dict_initializer(bool_imputation_dict)\n",
    "        self.default_cat_value = default_cat_value\n",
    "        self.default_num_value = default_num_value\n",
    "        self.default_bool_value = default_bool_value\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for category in self.cat_features:\n",
    "            X_transformed[category].fillna(self.cat_feature_imputer.get(category,\n",
    "                                                                        self.default_cat_value),\n",
    "                                           inplace=True)\n",
    "        for num_feature in self.num_features:\n",
    "            X_transformed[num_feature].fillna(self.num_feature_imputer.get(num_feature,\n",
    "                                                                           self.default_num_value),\n",
    "                                              inplace=True)\n",
    "        for bool_feature in self.bool_features:\n",
    "            X_transformed[bool_feature].fillna(self.bool_feature_imputer.get(bool_feature,\n",
    "                                                                             self.default_bool_value),\n",
    "                                               inplace=True)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MissingValuesImputer(cat_features, num_features, bool_features,\n",
    "                     num_features_imputation_dict={'years_elapsed':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "                                ('one_hot_encoder', OneHotEncoder(categories='auto',\n",
    "                                                                  handle_unknown='ignore',\n",
    "                                                                  sparse=False), cat_features),\n",
    "                                ('scaler', StandardScaler(), num_features),\n",
    "                                ('bool_encoder', BoolTranformer(), bool_features)],\n",
    "                                remainder='passthrough',\n",
    "                               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MissingValuesImputer(cat_features, num_features, bool_features,\n",
    "                     num_features_imputation_dict={'years_elapsed':1000})\n",
    "\n",
    "preprocessing_pipeline = Pipeline([('missing_values_imputer', imputer),\n",
    "          ('column_transformer',  column_transformer)], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing missing_values_imputer, total=   0.0s\n",
      "[ColumnTransformer]  (1 of 4) Processing one_hot_encoder, total=   0.2s\n",
      "[ColumnTransformer] ........ (2 of 4) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] .. (3 of 4) Processing bool_encoder, total=   0.0s\n",
      "[ColumnTransformer] ..... (4 of 4) Processing remainder, total=   0.0s\n",
      "[Pipeline]  (step 2 of 2) Processing column_transformer, total=   0.4s\n"
     ]
    }
   ],
   "source": [
    "features_transformed = preprocessing_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_transformer._n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = features_transformed[:,:-1], features_transformed[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = make_scorer(lambda y,preds : np.sqrt(mean_squared_error(y,preds)),\n",
    "                   greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366525.077890595"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(cross_val_score(tree, features, target, cv=10, scoring = rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(with_dummies, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('position', 0.0028728565598219397),\n",
       " ('number_rooms', 0.019173453126587636),\n",
       " ('floor_located', 0.0069971832574371885),\n",
       " ('number_of_floors_in_the_house', 0.02540956427815293),\n",
       " ('apartment_area', 0.5546683688167596),\n",
       " ('latitude', 0.002598432438930921),\n",
       " ('longitude', 0.005442356696076232),\n",
       " ('number_of_images_attached', 0.019544378686287174),\n",
       " ('len_of_description', 0.01215137866061125),\n",
       " ('num_of_uppercase_letters_in_description', 0.0036143076609968126),\n",
       " ('num_of_punctuations_in_description', 0.0027946062771268664),\n",
       " ('years_elapsed', 0.002186456075026997),\n",
       " ('is_bargain', 0.0013167599168236754),\n",
       " ('is_used', 0.00393724272409022),\n",
       " ('is_not_used', 0.0006789462932872677),\n",
       " ('in_installments', 0.010780911191414945),\n",
       " ('offer_type_Unknown', 0.0025883818984795133),\n",
       " ('offer_type_от застройщика', 2.671216353650564e-05),\n",
       " ('offer_type_от посредника', 0.003043048745137054),\n",
       " ('offer_type_от представителя застройщика', 0.0008794296993334059),\n",
       " ('offer_type_от представителя хозяина (без комиссионных)',\n",
       "  0.00020835503060244353),\n",
       " ('offer_type_от собственника', 0.0001251854083512648),\n",
       " ('wall_type_Unknown', 0.0),\n",
       " ('wall_type_армированный железобетон', 0.0),\n",
       " ('wall_type_блочно-кирпичный', 0.0003295804322470112),\n",
       " ('wall_type_бутовый камень', 0.0),\n",
       " ('wall_type_газобетон', 0.0),\n",
       " ('wall_type_газоблок', 0.0),\n",
       " ('wall_type_дерево и кирпич', 0.0),\n",
       " ('wall_type_железобетон', 0.0),\n",
       " ('wall_type_инкерманский камень', 0.0),\n",
       " ('wall_type_каркасно-каменная', 0.0),\n",
       " ('wall_type_керамзитобетон', 0.0),\n",
       " ('wall_type_керамический блок', 0.0),\n",
       " ('wall_type_керамический кирпич', 0.0),\n",
       " ('wall_type_кирпич', 0.004370758183831475),\n",
       " ('wall_type_монолит', 0.0007543065296119641),\n",
       " ('wall_type_монолитно-блочный', 7.47944095898292e-05),\n",
       " ('wall_type_монолитно-каркасный', 0.0004247041735873104),\n",
       " ('wall_type_монолитно-кирпичный', 3.124497032830699e-05),\n",
       " ('wall_type_монолитный железобетон', 0.00012336250057004317),\n",
       " ('wall_type_облицовочный кирпич', 0.0),\n",
       " ('wall_type_панель', 0.0030364696516758777),\n",
       " ('wall_type_пеноблок', 0.00020950575992752856),\n",
       " ('wall_type_ракушечник (ракушняк)', 3.743930078727492e-06),\n",
       " ('wall_type_сборно-монолитная', 0.0),\n",
       " ('wall_type_сборный железобетон', 0.0),\n",
       " ('wall_type_силикатный кирпич', 0.0),\n",
       " ('heating_Unknown', 1.0421707008427067e-06),\n",
       " ('heating_без отопления', 0.0007558045034505885),\n",
       " ('heating_индивидуальное', 0.0006504831147150668),\n",
       " ('heating_централизованное', 0.0005548193451902174),\n",
       " ('city_id_1', 0.0008075293335174758),\n",
       " ('city_id_2', 0.0),\n",
       " ('city_id_3', 0.0),\n",
       " ('city_id_4', 0.008458655567030923),\n",
       " ('city_id_5', 0.00040212368032814413),\n",
       " ('city_id_6', 0.0),\n",
       " ('city_id_7', 0.0005430456039226012),\n",
       " ('city_id_8', 0.0),\n",
       " ('city_id_9', 0.0),\n",
       " ('city_id_10', 0.15673444593066502),\n",
       " ('city_id_11', 0.00036412303570302907),\n",
       " ('city_id_12', 0.13848005451314094),\n",
       " ('city_id_13', 0.0),\n",
       " ('city_id_14', 0.0),\n",
       " ('city_id_15', 0.0006820709758195055),\n",
       " ('city_id_16', 0.0),\n",
       " ('city_id_17', 0.0),\n",
       " ('city_id_18', 0.0),\n",
       " ('city_id_19', 0.0),\n",
       " ('city_id_20', 0.0),\n",
       " ('city_id_22', 0.00012802090683180332),\n",
       " ('city_id_23', 0.0),\n",
       " ('city_id_24', 0.0),\n",
       " ('city_id_25', 0.0),\n",
       " ('city_id_26', 0.0),\n",
       " ('city_id_27', 0.0),\n",
       " ('city_id_28', 0.0),\n",
       " ('city_id_30', 0.0),\n",
       " ('city_id_32', 0.0),\n",
       " ('city_id_33', 0.0),\n",
       " ('city_id_34', 0.0),\n",
       " ('city_id_36', 0.0),\n",
       " ('city_id_39', 0.0),\n",
       " ('city_id_41', 0.0),\n",
       " ('city_id_42', 0.0),\n",
       " ('city_id_43', 0.0),\n",
       " ('city_id_44', 0.0),\n",
       " ('city_id_45', 0.0),\n",
       " ('city_id_49', 0.0),\n",
       " ('city_id_50', 0.0),\n",
       " ('city_id_55', 0.0),\n",
       " ('city_id_65', 0.0),\n",
       " ('city_id_68', 0.0),\n",
       " ('city_id_70', 0.0),\n",
       " ('city_id_72', 0.0),\n",
       " ('city_id_75', 0.0),\n",
       " ('city_id_76', 0.0),\n",
       " ('city_id_82', 0.0),\n",
       " ('city_id_84', 0.0),\n",
       " ('city_id_85', 0.0),\n",
       " ('city_id_94', 0.0),\n",
       " ('city_id_96', 0.0),\n",
       " ('city_id_100', 0.0),\n",
       " ('city_id_101', 0.0),\n",
       " ('city_id_113', 0.0),\n",
       " ('city_id_115', 0.0),\n",
       " ('city_id_116', 0.0),\n",
       " ('city_id_118', 0.0),\n",
       " ('city_id_119', 0.0),\n",
       " ('city_id_123', 0.0),\n",
       " ('city_id_130', 0.0),\n",
       " ('city_id_133', 0.0),\n",
       " ('city_id_134', 0.0),\n",
       " ('city_id_137', 0.0),\n",
       " ('city_id_140', 0.0),\n",
       " ('city_id_141', 0.0),\n",
       " ('city_id_144', 0.0),\n",
       " ('city_id_147', 0.0),\n",
       " ('city_id_149', 0.0),\n",
       " ('city_id_153', 0.0),\n",
       " ('city_id_154', 0.0),\n",
       " ('city_id_155', 0.0),\n",
       " ('city_id_157', 0.0),\n",
       " ('city_id_159', 0.0),\n",
       " ('city_id_161', 0.0),\n",
       " ('city_id_164', 0.0),\n",
       " ('city_id_168', 0.0),\n",
       " ('city_id_169', 0.0),\n",
       " ('city_id_170', 0.0),\n",
       " ('city_id_174', 0.0),\n",
       " ('city_id_176', 0.0),\n",
       " ('city_id_189', 0.0),\n",
       " ('city_id_195', 0.0),\n",
       " ('city_id_197', 0.0),\n",
       " ('city_id_199', 0.0),\n",
       " ('city_id_200', 0.0),\n",
       " ('city_id_202', 0.0),\n",
       " ('city_id_209', 0.0),\n",
       " ('city_id_210', 0.0),\n",
       " ('city_id_211', 0.0),\n",
       " ('city_id_212', 0.0),\n",
       " ('city_id_213', 0.0),\n",
       " ('city_id_214', 0.0),\n",
       " ('city_id_215', 0.0),\n",
       " ('city_id_216', 0.0),\n",
       " ('city_id_219', 0.0),\n",
       " ('city_id_220', 0.0001871276776114409),\n",
       " ('city_id_221', 0.0),\n",
       " ('city_id_223', 0.0),\n",
       " ('city_id_224', 0.0),\n",
       " ('city_id_225', 0.0),\n",
       " ('city_id_226', 0.0),\n",
       " ('city_id_228', 0.0),\n",
       " ('city_id_229', 0.0),\n",
       " ('city_id_231', 0.0),\n",
       " ('city_id_233', 0.0),\n",
       " ('city_id_234', 0.0),\n",
       " ('city_id_235', 0.0),\n",
       " ('city_id_238', 0.0),\n",
       " ('city_id_239', 0.0),\n",
       " ('city_id_241', 0.0),\n",
       " ('city_id_242', 0.0),\n",
       " ('city_id_252', 1.8801563944572926e-05),\n",
       " ('city_id_255', 0.0),\n",
       " ('city_id_265', 0.0),\n",
       " ('city_id_267', 0.0),\n",
       " ('city_id_284', 0.0),\n",
       " ('city_id_287', 0.0),\n",
       " ('city_id_288', 0.0),\n",
       " ('city_id_289', 0.0),\n",
       " ('city_id_291', 0.0),\n",
       " ('city_id_292', 0.0),\n",
       " ('city_id_293', 0.0),\n",
       " ('city_id_295', 0.0),\n",
       " ('city_id_300', 0.0),\n",
       " ('city_id_302', 0.0),\n",
       " ('city_id_303', 0.0),\n",
       " ('city_id_304', 0.0),\n",
       " ('city_id_305', 0.0),\n",
       " ('city_id_306', 0.0),\n",
       " ('city_id_307', 0.0),\n",
       " ('city_id_309', 0.0),\n",
       " ('city_id_310', 0.0),\n",
       " ('city_id_321', 0.0),\n",
       " ('city_id_328', 0.0),\n",
       " ('city_id_329', 0.0),\n",
       " ('city_id_331', 0.0),\n",
       " ('city_id_333', 0.0),\n",
       " ('city_id_334', 0.0),\n",
       " ('city_id_336', 0.0),\n",
       " ('city_id_337', 0.0),\n",
       " ('city_id_340', 0.0),\n",
       " ('city_id_341', 0.0),\n",
       " ('city_id_342', 0.00038596755791647417),\n",
       " ('city_id_345', 0.0),\n",
       " ('city_id_350', 0.0),\n",
       " ('city_id_353', 0.0),\n",
       " ('city_id_369', 0.0),\n",
       " ('city_id_376', 0.0),\n",
       " ('city_id_379', 0.0),\n",
       " ('city_id_392', 0.0),\n",
       " ('city_id_395', 0.0),\n",
       " ('city_id_397', 0.0),\n",
       " ('city_id_398', 0.0),\n",
       " ('city_id_409', 0.0),\n",
       " ('city_id_410', 0.0),\n",
       " ('city_id_412', 0.0),\n",
       " ('city_id_413', 0.0),\n",
       " ('city_id_416', 0.0),\n",
       " ('city_id_425', 0.0),\n",
       " ('city_id_427', 0.0),\n",
       " ('city_id_428', 0.0),\n",
       " ('city_id_429', 0.0),\n",
       " ('city_id_430', 0.0),\n",
       " ('city_id_431', 0.0),\n",
       " ('city_id_432', 0.0),\n",
       " ('city_id_433', 0.0),\n",
       " ('city_id_438', 0.0),\n",
       " ('city_id_441', 0.0),\n",
       " ('city_id_443', 0.0),\n",
       " ('city_id_448', 0.0),\n",
       " ('city_id_452', 0.0),\n",
       " ('city_id_453', 0.0),\n",
       " ('city_id_454', 0.0),\n",
       " ('city_id_461', 0.0),\n",
       " ('city_id_462', 0.0),\n",
       " ('city_id_469', 0.0),\n",
       " ('city_id_471', 0.0),\n",
       " ('city_id_478', 0.0),\n",
       " ('city_id_482', 0.0),\n",
       " ('city_id_484', 0.0),\n",
       " ('city_id_487', 0.0),\n",
       " ('city_id_489', 0.0),\n",
       " ('city_id_491', 0.0),\n",
       " ('city_id_492', 0.0),\n",
       " ('city_id_493', 0.0),\n",
       " ('city_id_494', 0.0),\n",
       " ('city_id_495', 0.0),\n",
       " ('city_id_498', 0.0),\n",
       " ('city_id_499', 0.0),\n",
       " ('city_id_500', 0.0),\n",
       " ('city_id_503', 0.0),\n",
       " ('city_id_504', 0.0),\n",
       " ('city_id_505', 0.0),\n",
       " ('city_id_511', 0.0),\n",
       " ('city_id_512', 0.0),\n",
       " ('city_id_515', 0.0),\n",
       " ('city_id_516', 0.0),\n",
       " ('city_id_518', 0.0),\n",
       " ('city_id_521', 0.0),\n",
       " ('city_id_525', 0.0),\n",
       " ('city_id_526', 0.0),\n",
       " ('city_id_527', 0.0),\n",
       " ('city_id_528', 0.0),\n",
       " ('city_id_531', 0.0),\n",
       " ('city_id_532', 0.0),\n",
       " ('city_id_540', 0.0),\n",
       " ('city_id_543', 0.0),\n",
       " ('city_id_560', 0.0),\n",
       " ('city_id_563', 0.0),\n",
       " ('city_id_586', 0.0),\n",
       " ('city_id_593', 0.0),\n",
       " ('city_id_597', 0.0),\n",
       " ('city_id_599', 0.0),\n",
       " ('city_id_602', 0.0),\n",
       " ('city_id_603', 0.0),\n",
       " ('city_id_604', 0.0),\n",
       " ('city_id_605', 0.0),\n",
       " ('city_id_609', 0.0),\n",
       " ('city_id_612', 0.0),\n",
       " ('city_id_613', 0.0),\n",
       " ('city_id_624', 0.0),\n",
       " ('city_id_625', 0.0),\n",
       " ('city_id_626', 0.0),\n",
       " ('city_id_636', 0.0),\n",
       " ('city_id_639', 0.0),\n",
       " ('city_id_643', 0.0),\n",
       " ('city_id_644', 0.0),\n",
       " ('city_id_645', 0.0),\n",
       " ('city_id_646', 0.0),\n",
       " ('city_id_647', 0.0),\n",
       " ('city_id_648', 0.00044909837319165156)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(with_dummies.columns, tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg = LGBMRegressor(max_depth=30,\n",
    "                        num_leaves=128,\n",
    "                        learning_rate=.05,\n",
    "                        n_estimators=500,\n",
    "                        bagging_fraction=.6,\n",
    "                        feature_fraction=.6,\n",
    "                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308943.55295862857"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(cross_val_score(lgb_reg, features, target, cv=5, scoring =rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569108979589639"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(lgb_reg, with_dummies, target, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.jblib']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(['hello_there'],'test.jblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello_there']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('test.jblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = with_dummies.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.9 ms ± 4.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lgb_reg.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.6, boosting_type='gbdt', class_weight=None,\n",
       "              colsample_bytree=1.0, feature_fraction=0.6,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=30,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=500, n_jobs=-1, num_leaves=128, objective=None,\n",
       "              random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_reg.fit(with_dummies, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMRegressor'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_reg.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x122c438f0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(features, \n",
    "                                                    target,\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = map(\n",
    "    lambda x: torch.from_numpy(x).float(), [train_x, test_x, train_y, test_y]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train,\n",
    "                              Y_train)\n",
    "\n",
    "test_dataset = TensorDataset(X_test,\n",
    "                             Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceRegressorDNN(nn.Module):\n",
    "    def __init__(self, input_dim, \n",
    "                activation_function):\n",
    "        \n",
    "#         assert(type(neurons) is list, f\"{neurons} should a list of neurons\")\n",
    "        \n",
    "        super(PriceRegressorDNN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.activation_function = activation_function\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "#         self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Linear function  # LINEAR\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation_function(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = self.activation_function(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PriceRegressorDNN(X_train.shape[1], nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=learning_rate,\n",
    "                            momentum=.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(Y_pred, Y_true):\n",
    "    rmse_val =  torch.sqrt(torch.mean((torch.pow(Y_pred - Y_true, 2))))\n",
    "#     print(rmse_val.item())\n",
    "#     if np.isnan(rmse_val.item()):\n",
    "#         print(Y_pred)\n",
    "#         print(Y_true)\n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(Y_pred, Y_true):\n",
    "    mse = torch.mean((torch.pow(Y_pred - Y_true, 2)))\n",
    "    return 1 - mse/torch.var(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_squared_logarithmic_loss(output, target):\n",
    "#     loss = torch.mean((torch.log(target+1) - torch.log(output+1))**2)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_logarithmic_loss(torch.Tensor([100,100]),torch.Tensor([1000,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion(torch.zeros(64,1),torch.ones(64,1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 296236.750. RMSE: 471544.946\n",
      "Iteration: 1000. Loss: 302228.594. RMSE: 497495.805\n",
      "Iteration: 1500. Loss: 269063.125. RMSE: 439105.572\n",
      "Iteration: 2000. Loss: 265578.625. RMSE: 436933.191\n",
      "Iteration: 2500. Loss: 400204.406. RMSE: 488300.735\n",
      "Iteration: 3000. Loss: 240989.672. RMSE: 425107.865\n",
      "Iteration: 3500. Loss: 323623.500. RMSE: 501193.130\n",
      "Iteration: 4000. Loss: 337388.750. RMSE: 449636.922\n",
      "Iteration: 4500. Loss: 276032.562. RMSE: 414188.242\n",
      "Iteration: 5000. Loss: 330324.812. RMSE: 472789.098\n",
      "Iteration: 5500. Loss: 260807.500. RMSE: 412609.455\n",
      "Iteration: 6000. Loss: 319650.156. RMSE: 502228.542\n",
      "Iteration: 6500. Loss: 294953.875. RMSE: 433779.196\n",
      "Iteration: 7000. Loss: 303054.094. RMSE: 445753.643\n",
      "Iteration: 7500. Loss: 290048.250. RMSE: 419041.165\n",
      "Iteration: 8000. Loss: 269924.438. RMSE: 410508.481\n",
      "Iteration: 8500. Loss: 351788.250. RMSE: 488137.569\n",
      "Iteration: 9000. Loss: 286592.250. RMSE: 396365.756\n",
      "Iteration: 9500. Loss: 237609.344. RMSE: 389933.280\n",
      "Iteration: 10000. Loss: 285755.750. RMSE: 413087.706\n",
      "Iteration: 10500. Loss: 283363.656. RMSE: 403385.784\n",
      "Iteration: 11000. Loss: 281232.188. RMSE: 392730.678\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-2c05f501a084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# clear gradients for next train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (train_features, labels_train) in enumerate(train_loader):\n",
    "#         print(labels)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "            \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(train_features)\n",
    "        \n",
    "        loss = criterion(outputs, labels_train)\n",
    "#         print(loss)\n",
    "        \n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        \n",
    "\n",
    "        iteration += 1\n",
    "    \n",
    "        \n",
    "        if iteration % 500 == 0:\n",
    "            \n",
    "            rmses = []\n",
    "            # Calculate RMSE\n",
    "            # Iterate through test dataset\n",
    "            for test_features, labels_test in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(test_features)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                rmses.append(rmse(outputs, labels_test).item())\n",
    "                \n",
    "            mean_rmse = np.mean(np.array(rmses))\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {:.3f}. RMSE: {:.3f}'.format(iteration, loss.item(), mean_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295401.4066815665"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(lgb_reg.predict(test_x) ,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092784156813776"
      ]
     },
     "execution_count": 1032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(lgb_reg.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(222835.9062, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(model(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_test).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(332933.1562, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(model(X_test), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() ,\"test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriceRegressorDNN(\n",
       "  (fc1): Linear(in_features=284, out_features=512, bias=True)\n",
       "  (activation_function): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('one_hot_encoder',\n",
       "                                 OneHotEncoder(categorical_features=None,\n",
       "                                               categories='auto', drop=None,\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='ignore',\n",
       "                                               n_values=None, sparse=False),\n",
       "                                 ['offer_type', 'wall_type', 'heating',\n",
       "                                  'city_id']),\n",
       "                                ('scaler',\n",
       "                                 StandardSc...\n",
       "                                 ['position', 'len_of_description',\n",
       "                                  'floor_located',\n",
       "                                  'number_of_floors_in_the_house', 'longitude',\n",
       "                                  'apartment_area', 'years_elapsed',\n",
       "                                  'num_of_punctuations_in_description',\n",
       "                                  'number_rooms', 'latitude',\n",
       "                                  'num_of_uppercase_letters_in_description',\n",
       "                                  'number_of_images_attached']),\n",
       "                                ('bool_encoder', BoolTranformer(),\n",
       "                                 ['is_bargain', 'is_used', 'is_not_used',\n",
       "                                  'in_installments'])],\n",
       "                  verbose=2)"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('assets/column_transformer.jblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
